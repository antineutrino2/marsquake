{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b8840c",
   "metadata": {},
   "source": [
    "# Mars Seismic Data Visualization\n",
    "\n",
    "\n",
    "This is a notebook to download and visualize Mars seismic event data from the xxxx 3-component seismiometer\n",
    "\n",
    "Here is a great readme on downloading the data and formatting it from NASA: https://pds-geosciences.wustl.edu/insight/urn-nasa-pds-insight_seis/readme.txt\n",
    "\n",
    "First need to:\n",
    " -  Choose the events by downloading the catalog, remove events that have default lat/long (4.5024, 135.6234)\n",
    " -  Download the raw data automatically from NASA (only horizontal component currently (BHU)\n",
    " -  Aggregate the data and compute differentiation\n",
    " -  Plot the events in panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd4fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: xb.elyse.02.bhu.2022.124.3.a\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# place to save data\n",
    "basedir = \"C:/home/data/mars/\"\n",
    "\n",
    "\n",
    "def getEvents(starttime=None,endtime=None):\n",
    "    url = \"https://service.iris.edu/irisws/mars-event/1/query?minmagnitude=0&format=text\"\n",
    "    response = requests.get(url)\n",
    "    plain_text = response.text\n",
    "    lines = plain_text.strip().split('\\n')\n",
    "    data = [line.split('|') for line in lines]\n",
    "    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    df = df[(df['Latitude']!=\"4.5024\") & (df['Latitude']!=\"135.6234\")]\n",
    "    df['Sol'] = df['ContributorID'].str[1:4]\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    df['Year'] = df['Time'].dt.year.astype(str)\n",
    "    df['DOY'] = (df['Time'].dt.dayofyear).astype(str).str.zfill(3)\n",
    "    if starttime:\n",
    "        df = df[df['Time']>starttime]\n",
    "    if endtime:\n",
    "        df = df[df['Time']<endtime]\n",
    "    return df\n",
    "\n",
    "events = getEvents()\n",
    "\n",
    "# Download the seismicity data test (need come up with a list for event format)\n",
    "# url_base = \"https://pds-geosciences.wustl.edu/insight/urn-nasa-pds-insight_seis/data/xb/continuous_waveform/elyse/2021/122/\"\n",
    "# file_name = \"xb.elyse.02.bhu.2021.122.7.a.csv\"\n",
    "# url = url_base+file_name\n",
    "\n",
    "# Time the Insight lander landed on \n",
    "lander_time = pd.to_datetime(\"2018-11-26T11:52:59.0Z\")\n",
    "\n",
    "def download_raw_data(url,file_name,save = False):\n",
    "    d = pd.read_csv(url,skiprows=19, delimiter=',')\n",
    "    # Option to save data\n",
    "    if save:\n",
    "        if not os.path.exists(basedir):\n",
    "            os.makedirs(basedir)\n",
    "        d.to_csv(basedir+file_name,index=False)\n",
    "    return d\n",
    "\n",
    "def download_all_events(allevents):\n",
    "    for indx,event in allevents.iterrows():\n",
    "        doy = event['DOY']\n",
    "        year = event['Year']\n",
    "        url_base = f\"https://pds-geosciences.wustl.edu/insight/urn-nasa-pds-insight_seis/data/xb/continuous_waveform/elyse/{year}/{doy}/\"\n",
    "        for ix in range(15):\n",
    "            try:\n",
    "                # Only horizontal component being grabbed\n",
    "                file_name = f\"xb.elyse.02.bhu.{year}.{doy}.{ix}.a.csv\"\n",
    "                url = url_base+file_name\n",
    "                download_raw_data(url,file_name,save=True)\n",
    "                print(f'downloaded {file_name}')\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "def read_downloaded_events(levents=None):\n",
    "    dlist = []\n",
    "    for file in os.listdir(basedir):\n",
    "        sub = pd.read_csv(basedir+file).drop(columns=['Unnamed: 0'],errors='ignore').rename(columns={\" Sample\":\"Sample\"})\n",
    "        sub['name'] = os.path.splitext(os.path.basename(file))[0]\n",
    "        print('reading:',os.path.splitext(os.path.basename(file))[0])\n",
    "        dlist.append(sub)\n",
    "    return dlist\n",
    "                \n",
    "\n",
    "# Uncomment to download all events to disk in base_dir\n",
    "#download_all_events(events)\n",
    "\n",
    "dlist = read_downloaded_events()\n",
    "\n",
    "rdata = pd.concat(dlist)\n",
    "rdata['Time'] = pd.to_datetime(rdata['Time'])\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38491989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Sample</th>\n",
       "      <th>name</th>\n",
       "      <th>Time_elapsed</th>\n",
       "      <th>Norm_Time</th>\n",
       "      <th>Amplitude_Normalized</th>\n",
       "      <th>Amplitude_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-04 00:00:00.012000+00:00</td>\n",
       "      <td>-4239</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.492962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-04 00:00:00.062000+00:00</td>\n",
       "      <td>-4696</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 00:00:00.050000</td>\n",
       "      <td>5.787047e-07</td>\n",
       "      <td>0.492817</td>\n",
       "      <td>-457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-04 00:00:00.112000+00:00</td>\n",
       "      <td>-4809</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 00:00:00.100000</td>\n",
       "      <td>1.157409e-06</td>\n",
       "      <td>0.492781</td>\n",
       "      <td>-113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-04 00:00:00.162000+00:00</td>\n",
       "      <td>-4836</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 00:00:00.150000</td>\n",
       "      <td>1.736114e-06</td>\n",
       "      <td>0.492772</td>\n",
       "      <td>-27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-04 00:00:00.212000+00:00</td>\n",
       "      <td>-4349</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 00:00:00.200000</td>\n",
       "      <td>2.314819e-06</td>\n",
       "      <td>0.492927</td>\n",
       "      <td>487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727993</th>\n",
       "      <td>2022-05-04 23:59:59.662000+00:00</td>\n",
       "      <td>-4776</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 23:59:59.650000</td>\n",
       "      <td>9.999977e-01</td>\n",
       "      <td>0.492792</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727994</th>\n",
       "      <td>2022-05-04 23:59:59.712000+00:00</td>\n",
       "      <td>-4563</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 23:59:59.700000</td>\n",
       "      <td>9.999983e-01</td>\n",
       "      <td>0.492859</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727995</th>\n",
       "      <td>2022-05-04 23:59:59.762000+00:00</td>\n",
       "      <td>-3126</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 23:59:59.750000</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>0.493315</td>\n",
       "      <td>1437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727996</th>\n",
       "      <td>2022-05-04 23:59:59.812000+00:00</td>\n",
       "      <td>-878</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 23:59:59.800000</td>\n",
       "      <td>9.999994e-01</td>\n",
       "      <td>0.494029</td>\n",
       "      <td>2248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727997</th>\n",
       "      <td>2022-05-04 23:59:59.862000+00:00</td>\n",
       "      <td>-1393</td>\n",
       "      <td>xb.elyse.02.bhu.2022.124.3.a</td>\n",
       "      <td>0 days 23:59:59.850000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.493866</td>\n",
       "      <td>-515.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1727998 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Time  Sample  \\\n",
       "0       2022-05-04 00:00:00.012000+00:00   -4239   \n",
       "1       2022-05-04 00:00:00.062000+00:00   -4696   \n",
       "2       2022-05-04 00:00:00.112000+00:00   -4809   \n",
       "3       2022-05-04 00:00:00.162000+00:00   -4836   \n",
       "4       2022-05-04 00:00:00.212000+00:00   -4349   \n",
       "...                                  ...     ...   \n",
       "1727993 2022-05-04 23:59:59.662000+00:00   -4776   \n",
       "1727994 2022-05-04 23:59:59.712000+00:00   -4563   \n",
       "1727995 2022-05-04 23:59:59.762000+00:00   -3126   \n",
       "1727996 2022-05-04 23:59:59.812000+00:00    -878   \n",
       "1727997 2022-05-04 23:59:59.862000+00:00   -1393   \n",
       "\n",
       "                                 name           Time_elapsed     Norm_Time  \\\n",
       "0        xb.elyse.02.bhu.2022.124.3.a        0 days 00:00:00  0.000000e+00   \n",
       "1        xb.elyse.02.bhu.2022.124.3.a 0 days 00:00:00.050000  5.787047e-07   \n",
       "2        xb.elyse.02.bhu.2022.124.3.a 0 days 00:00:00.100000  1.157409e-06   \n",
       "3        xb.elyse.02.bhu.2022.124.3.a 0 days 00:00:00.150000  1.736114e-06   \n",
       "4        xb.elyse.02.bhu.2022.124.3.a 0 days 00:00:00.200000  2.314819e-06   \n",
       "...                               ...                    ...           ...   \n",
       "1727993  xb.elyse.02.bhu.2022.124.3.a 0 days 23:59:59.650000  9.999977e-01   \n",
       "1727994  xb.elyse.02.bhu.2022.124.3.a 0 days 23:59:59.700000  9.999983e-01   \n",
       "1727995  xb.elyse.02.bhu.2022.124.3.a 0 days 23:59:59.750000  9.999988e-01   \n",
       "1727996  xb.elyse.02.bhu.2022.124.3.a 0 days 23:59:59.800000  9.999994e-01   \n",
       "1727997  xb.elyse.02.bhu.2022.124.3.a 0 days 23:59:59.850000  1.000000e+00   \n",
       "\n",
       "         Amplitude_Normalized  Amplitude_Diff  \n",
       "0                    0.492962             NaN  \n",
       "1                    0.492817          -457.0  \n",
       "2                    0.492781          -113.0  \n",
       "3                    0.492772           -27.0  \n",
       "4                    0.492927           487.0  \n",
       "...                       ...             ...  \n",
       "1727993              0.492792           426.0  \n",
       "1727994              0.492859           213.0  \n",
       "1727995              0.493315          1437.0  \n",
       "1727996              0.494029          2248.0  \n",
       "1727997              0.493866          -515.0  \n",
       "\n",
       "[1727998 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decimate_and_filter(df, col_name, time_col_name, name_col_name, original_interval, desired_interval, window_size):\n",
    "    unique_names = df[name_col_name].unique()\n",
    "\n",
    "    result_dfs = []\n",
    "\n",
    "    for name in unique_names:\n",
    "        # Filter the input DataFrame by the unique name\n",
    "        filtered_df = df[df[name_col_name] == name]\n",
    "\n",
    "        # Get the original data from the filtered DataFrame\n",
    "        time_series_data = filtered_df[col_name].values\n",
    "        time_series_time = filtered_df[time_col_name].values\n",
    "\n",
    "        # Define the original and desired sampling rates (in Hz)\n",
    "        original_frequency = 1 / original_interval\n",
    "        desired_frequency = 1 / desired_interval\n",
    "\n",
    "        # Compute the decimation factor\n",
    "        decimation_factor = int(original_frequency * desired_interval)\n",
    "\n",
    "        # Define the sinc interpolation function\n",
    "        def sinc_interp(x, s, factor):\n",
    "            sinc = lambda x: np.sinc(x / factor)\n",
    "            return np.dot(s, sinc(np.arange(len(s)) - x))\n",
    "\n",
    "        # Perform the sinc interpolation and decimation\n",
    "        decimated_data = []\n",
    "        decimated_time = []\n",
    "        for i in range(0, len(time_series_data), decimation_factor):\n",
    "            decimated_data.append(sinc_interp(i, time_series_data[i:i+decimation_factor], decimation_factor))\n",
    "            decimated_time.append(time_series_time[i])\n",
    "\n",
    "        decimated_data = np.array(decimated_data)\n",
    "        decimated_time = np.array(decimated_time)\n",
    "\n",
    "        # Create a pandas DataFrame with the decimated data and time\n",
    "        decimated_df = pd.DataFrame({time_col_name: decimated_time, col_name: decimated_data, name_col_name: [name] * len(decimated_data)})\n",
    "\n",
    "        # Apply a rolling mean filter with the desired window size\n",
    "        #decimated_df[f'{col_name}_rolling_mean'] = decimated_df[col_name].rolling(window=window_size).mean()\n",
    "\n",
    "        result_dfs.append(decimated_df)\n",
    "\n",
    "    # Concatenate the result DataFrames\n",
    "    result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def add_normalized_time_index(df, time_col_name, name_col_name):\n",
    "    unique_names = df[name_col_name].unique()\n",
    "    result_dfs = []\n",
    "\n",
    "    for name in unique_names:\n",
    "        # Filter the input DataFrame by the unique name\n",
    "        filtered_df = df[df[name_col_name] == name].copy()\n",
    "\n",
    "        # Calculate the total duration of the signal\n",
    "        total_duration = filtered_df[time_col_name].max() - filtered_df[time_col_name].min()\n",
    "\n",
    "        # Calculate the time elapsed since the start of the signal\n",
    "        filtered_df['Time_elapsed'] = filtered_df[time_col_name] - filtered_df[time_col_name].min()\n",
    "\n",
    "        # Normalize the time index\n",
    "        filtered_df['Norm_Time'] = filtered_df['Time_elapsed'] / total_duration\n",
    "\n",
    "        result_dfs.append(filtered_df)\n",
    "\n",
    "    # Concatenate the result DataFrames\n",
    "    result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def process_data(data):\n",
    "    data['Time'] = pd.to_datetime(data['Time'])\n",
    "    data['Amplitude_Normalized'] = (data['Sample']-min(data['Sample']))/(max(data['Sample'])-min(data['Sample']))\n",
    "    data['Amplitude_Diff'] = data['Sample'].diff()\n",
    "    return data\n",
    "\n",
    "# Decimate the data to 1-minute resolution and apply a rolling mean filter with a window size of 5\n",
    "original_interval = 0.05  # 50 ms\n",
    "desired_interval = 1  # 1 second\n",
    "window_size = 5\n",
    "#data = decimate_and_filter(rdata, 'Sample', 'Time', 'name', original_interval, desired_interval, window_size)\n",
    "data = add_normalized_time_index(rdata, 'Time', 'name')\n",
    "\n",
    "data = process_data(data)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbceb0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "def plotEventPanels(data,yax=\"Amplitude_Diff\",xax=\"Time\"):\n",
    "    # Get the unique event names\n",
    "    event_names = data['name'].unique()\n",
    "\n",
    "    # Create subplots with a shared x-axis\n",
    "    fig = sp.make_subplots(rows=len(event_names), cols=1, shared_xaxes=True, subplot_titles=event_names, vertical_spacing=0.05)\n",
    "\n",
    "    # Loop through event names and add a trace for each event\n",
    "    for idx, event_name in enumerate(event_names):\n",
    "        event_data = data[data['name'] == event_name]\n",
    "\n",
    "        trace = go.Scatter(\n",
    "            x=event_data[xax],\n",
    "            y=event_data[yax],\n",
    "            mode=\"lines\",\n",
    "            name=event_name,\n",
    "            line=dict(width=2),\n",
    "        )\n",
    "\n",
    "        fig.add_trace(trace, row=idx + 1, col=1)\n",
    "\n",
    "    # Update the layout with axis labels and a title\n",
    "    fig.update_layout(\n",
    "        title=\"Seismic Data from InSight SEIS\",\n",
    "        xaxis=dict(title=\"Date Time\"),\n",
    "        yaxis=dict(title=\"Amplitude Normalized\"),\n",
    "    )\n",
    "\n",
    "    # Display the interactive plot\n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig)\n",
    "\n",
    "# Set column names\n",
    "yax = \"Amplitude_Diff\"\n",
    "xax = \"Norm_Time\"\n",
    "plotEventPanels(data,yax=yax,xax=xax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Amplitude Spectrums and plot for each event\n",
    "\n",
    "# Set column names\n",
    "yax = \"Sample\"\n",
    "xax = \"Time\"\n",
    "\n",
    "# Get the unique event names\n",
    "event_names = data['name'].unique()\n",
    "\n",
    "# Initialize an empty dictionary to store the FFT results\n",
    "fft_results = {}\n",
    "\n",
    "# Loop through event names and calculate the FFT for each event\n",
    "for event_name in event_names:\n",
    "    event_data = data[data['name'] == event_name]\n",
    "    \n",
    "    # Extract the time series and normalize it if necessary\n",
    "    time_series = event_data[yax].values\n",
    "    \n",
    "    # Perform the FFT\n",
    "    fft_output = np.fft.fft(time_series)\n",
    "    \n",
    "    # Store the FFT output in the results dictionary\n",
    "    fft_results[event_name] = fft_output\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the number of data points in the time series\n",
    "n = len(data[xax].values)\n",
    "\n",
    "# Calculate the frequency values corresponding to the FFT output\n",
    "freqs = np.fft.fftfreq(n)\n",
    "\n",
    "# Create subplots with a shared x-axis\n",
    "fig = sp.make_subplots(rows=len(event_names), cols=1, shared_xaxes=True, subplot_titles=event_names, vertical_spacing=0.05)\n",
    "\n",
    "# Loop through event names and add a trace for each event's amplitude spectrum\n",
    "for idx, event_name in enumerate(event_names):\n",
    "    # Retrieve the FFT output from the results dictionary\n",
    "    fft_output = fft_results[event_name]\n",
    "    \n",
    "    # Calculate the amplitude spectrum\n",
    "    amplitude_spectrum = np.abs(fft_output)\n",
    "    \n",
    "    trace = go.Scatter(\n",
    "        x=freqs,\n",
    "        y=amplitude_spectrum,\n",
    "        mode=\"lines\",\n",
    "        name=event_name,\n",
    "        line=dict(width=2),\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(trace, row=idx + 1, col=1)\n",
    "\n",
    "# Update the layout with axis labels and a title\n",
    "fig.update_layout(\n",
    "    title=\"Amplitude Spectrum of Seismic Data from InSight SEIS\",\n",
    "    xaxis=dict(title=\"Frequency (Hz)\"),\n",
    "    yaxis=dict(title=\"Amplitude\"),\n",
    ")\n",
    "\n",
    "# Display the interactive plot\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "plotly.offline.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a80325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
